{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Exercise\n",
    "\n",
    "REVISIONS| |\n",
    "---------| |\n",
    "2018-0318| CEF, initial.\n",
    "2018-0321| CEF, synced with MLP moon exercise.\n",
    "2018-0323| CEF, minor updated and spell checked.\n",
    "\n",
    "\n",
    "## Keras Multi-Layer Perceptrons (MLP's) on MNIST-data\n",
    "\n",
    "\n",
    "### Qa Using a Keras MLP on the MNIST-data\n",
    "\n",
    "Now, make a Keras `Sequential` model and fit it to the MNIST data, re-using as much of the code form the `mlp_moon.ipynb` as you can.\n",
    "\n",
    "NOTE: you probably need to scale/normalize the MNIST data before a fit, and no 2D-decision boundaries can be drawn from the 784-dimension MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2666 - acc: 0.9186 - val_loss: 0.0622 - val_acc: 0.9799\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0888 - acc: 0.9736 - val_loss: 0.0393 - val_acc: 0.9853\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0667 - acc: 0.9800 - val_loss: 0.0342 - val_acc: 0.9884\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0555 - acc: 0.9839 - val_loss: 0.0323 - val_acc: 0.9888\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0470 - acc: 0.9861 - val_loss: 0.0322 - val_acc: 0.9898\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0417 - acc: 0.9872 - val_loss: 0.0280 - val_acc: 0.9908\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0385 - acc: 0.9883 - val_loss: 0.0288 - val_acc: 0.9912\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0349 - acc: 0.9892 - val_loss: 0.0273 - val_acc: 0.9912\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0326 - acc: 0.9899 - val_loss: 0.0299 - val_acc: 0.9900\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0252 - val_acc: 0.9923\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0280 - acc: 0.9918 - val_loss: 0.0272 - val_acc: 0.9920\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0273 - acc: 0.9918 - val_loss: 0.0325 - val_acc: 0.9901\n",
      "Test loss: 0.03246526312285332\n",
      "Test accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa..\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Repeat Grp10's Go at the Search Quest\n",
    "\n",
    "Now, try to crank up the accuracy for the model using the MNIST data, you could follow the NN layout found by ITMAL Grp10 using an MLP in the Scikit-learn framework.\n",
    "\n",
    "Basically, they created a seven-layer `sklearn.neural_network.MLPClassifier`, with layer sizes 20-50-70-100-70-50-20. Their Scikit-learn `MLPClassifier` constructor looked like  \n",
    "\n",
    "```python\n",
    "CTOR for best model: MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(20, 50, 70, 100, 70, 50, 20),\n",
    "       learning_rate='adaptive', learning_rate_init=0.001, max_iter=500,\n",
    "       momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "       power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
    "       tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "       warm_start=False)\n",
    "```\n",
    "\n",
    "See, if you can create a somewhat similar model in Keras, but feel free to replace any of the other hyperparameters (where some are not even present in Keras).\n",
    "\n",
    "That best accuracy can you get from your model---for your validation or test set? \n",
    "\n",
    "For the journal describe your investigation methods and results in your quest-quest for a higher accuracy score on MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 30)        780       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 17280)             0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 20)                345620    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 70)                3570      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               7100      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 70)                7070      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 50)                3550      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 369,250\n",
      "Trainable params: 369,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.2937 - acc: 0.2841 - val_loss: 2.2700 - val_acc: 0.3586\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 1.8352 - acc: 0.3714 - val_loss: 0.8396 - val_acc: 0.7379\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.4817 - acc: 0.8544 - val_loss: 0.3413 - val_acc: 0.8994\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3079 - acc: 0.9111 - val_loss: 0.2522 - val_acc: 0.9238\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2419 - acc: 0.9299 - val_loss: 0.2156 - val_acc: 0.9388\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2024 - acc: 0.9417 - val_loss: 0.1737 - val_acc: 0.9474\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1715 - acc: 0.9505 - val_loss: 0.1572 - val_acc: 0.9529\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1502 - acc: 0.9564 - val_loss: 0.1397 - val_acc: 0.9604\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1348 - acc: 0.9608 - val_loss: 0.1216 - val_acc: 0.9638\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1213 - acc: 0.9650 - val_loss: 0.1247 - val_acc: 0.9639\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1106 - acc: 0.9679 - val_loss: 0.1046 - val_acc: 0.9663\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1038 - acc: 0.9697 - val_loss: 0.0964 - val_acc: 0.9707\n",
      "Test loss: 0.096425878213346\n",
      "Test accuracy: 0.9707\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qb...\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.001, decay=1e-08, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Qc Make a Keras Compatible F1-score\n",
    "\n",
    "One drawback of Keres is the smaller set of score (metric) functions. Try to create your own F1-score that is compatible with the Keras categorical data.\n",
    "\n",
    "Perhaps you can base your implementation on the Keras accuracy function\n",
    "\n",
    "```python\n",
    "def categorical_accuracy(y_true, y_pred):\n",
    "    return K.cast(K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)), K.floatx())\n",
    "```\n",
    "\n",
    "BUT BEWARE: you need to be able to interpret the TensorFlow tensor data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: [OPTIONAL] Qc.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
